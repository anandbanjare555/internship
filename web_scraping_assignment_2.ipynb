{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad55d03",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.shine.com/\n",
    "# 2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "# 3. Then click the searchbutton.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1032dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\anand\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\anand\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ec2bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a58ff7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6291448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6c8380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter designation as required in the question\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys('Data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f44c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter location as required in the question\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fae94935",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH, \"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79a09eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1431ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags:\n",
    "    titles=i.text\n",
    "    job_titles.append(titles)\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')  \n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6d76392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41a7de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>diraa hr services hiring for mncs</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>Bangalore\\n+18</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>15 to &gt;25 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeler data</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Modeller</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Full time Opportunity-Networking Advisor-Cisco...</td>\n",
       "      <td>Bangalore\\n+5</td>\n",
       "      <td>ntt data information processing ser...</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst Hiring Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst Hiring Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ML Data Scientist</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>gujarat facility services hiring fo...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hiring for Business Analyst</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hiring for Business Analyst</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Engineer-OBIEE</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>infosys limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data typing/computer operator/work from home/p...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>fondstaff private limited</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Intelligence Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>digitalcube consultancy</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Assistant Vice President</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>whiteslips global services private ...</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Walkin Drive for Power Bi</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>hucon solutions india pvt.ltd.</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>aereo</td>\n",
       "      <td>7 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Modeler _Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>varite india private limited</td>\n",
       "      <td>4 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Warehouse _ Manager For bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Data Warehouse _Manager</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Business Development Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>rianshi developers private limited</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Analytics Manager</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>vaishnavi services</td>\n",
       "      <td>15 to &gt;25 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Hiring Now for a Part-Time Data Entry Operator...</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>pick bright hr solution</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Software Developer Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title        location  \\\n",
       "0                                   Lead Data Analyst       Bangalore   \n",
       "1                                        Data Analyst   Bangalore\\n+3   \n",
       "2                            Vacancy For Data Analyst  Bangalore\\n+14   \n",
       "3                               Clinical Data Analyst   Bangalore\\n+6   \n",
       "4                                     Data Management  Bangalore\\n+18   \n",
       "5                                   Data Modeler data       Bangalore   \n",
       "6                                       Data Modeller       Bangalore   \n",
       "7                              Data Modeler Bangalore       Bangalore   \n",
       "8                                        Data Modeler       Bangalore   \n",
       "9                               Clinical Data Analyst   Bangalore\\n+4   \n",
       "10  Full time Opportunity-Networking Advisor-Cisco...   Bangalore\\n+5   \n",
       "11                                   Data Engineer Ii   Bangalore\\n+9   \n",
       "12         Data Analyst Hiring Fresher and Experience  Bangalore\\n+13   \n",
       "13         Data Analyst Hiring Fresher and Experience  Bangalore\\n+13   \n",
       "14                                  ML Data Scientist   Bangalore\\n+3   \n",
       "15                        Hiring for Business Analyst  Bangalore\\n+15   \n",
       "16                        Hiring for Business Analyst  Bangalore\\n+15   \n",
       "17                                       Data Modeler   Bangalore\\n+6   \n",
       "18                                Data Engineer-OBIEE   Bangalore\\n+1   \n",
       "19                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "20                                       Data Analyst       Bangalore   \n",
       "21  Data typing/computer operator/work from home/p...       Bangalore   \n",
       "22                          Data Intelligence Analyst   Bangalore\\n+6   \n",
       "23                                Azure Data Engineer   Bangalore\\n+1   \n",
       "24  Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14   \n",
       "25                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "26                           Assistant Vice President   Bangalore\\n+8   \n",
       "27                             Data Modeler Bangalore       Bangalore   \n",
       "28                          Walkin Drive for Power Bi   Bangalore\\n+1   \n",
       "29                                Lead Data Scientist   Bangalore\\n+1   \n",
       "30                            Data Modeler _Bangalore       Bangalore   \n",
       "31                                      Data Engineer       Bangalore   \n",
       "32             Data Warehouse _ Manager For bangalore       Bangalore   \n",
       "33                            Data Warehouse _Manager       Bangalore   \n",
       "34                                      Data Engineer   Bangalore\\n+9   \n",
       "35                       Business Development Analyst   Bangalore\\n+9   \n",
       "36                                  Analytics Manager   Bangalore\\n+9   \n",
       "37                      Data Scientist Urgent Vacancy  Bangalore\\n+14   \n",
       "38  Hiring Now for a Part-Time Data Entry Operator...   Bangalore\\n+9   \n",
       "39                     Software Developer Recruitment  Bangalore\\n+15   \n",
       "\n",
       "                              company_name     experience  \n",
       "0            ara resources private limited     4 to 9 Yrs  \n",
       "1        diraa hr services hiring for mncs      0 to 1 Yr  \n",
       "2                 yogita staffing solution     0 to 3 Yrs  \n",
       "3                            techno endura      0 to 1 Yr  \n",
       "4                   future solution centre  15 to >25 Yrs  \n",
       "5   boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "6   boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "7   boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "8   boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "9                          quiscon biotech     0 to 2 Yrs  \n",
       "10  ntt data information processing ser...   10 to 20 Yrs  \n",
       "11                 v-tech data outsourcing      0 to 1 Yr  \n",
       "12                       kavya interprises     0 to 4 Yrs  \n",
       "13                       kavya interprises     0 to 4 Yrs  \n",
       "14  gujarat facility services hiring fo...     5 to 8 Yrs  \n",
       "15                      renuka interprises     0 to 4 Yrs  \n",
       "16                      renuka interprises     0 to 4 Yrs  \n",
       "17                     ltimindtree limited    5 to 10 Yrs  \n",
       "18                     ltimindtree limited    5 to 10 Yrs  \n",
       "19                           techno endura      0 to 1 Yr  \n",
       "20                         infosys limited     4 to 6 Yrs  \n",
       "21               fondstaff private limited     0 to 4 Yrs  \n",
       "22                         quiscon biotech      0 to 1 Yr  \n",
       "23                 digitalcube consultancy    7 to 12 Yrs  \n",
       "24                yogita staffing solution     0 to 3 Yrs  \n",
       "25                           techno endura      0 to 1 Yr  \n",
       "26  whiteslips global services private ...   10 to 20 Yrs  \n",
       "27  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "28          hucon solutions india pvt.ltd.     2 to 4 Yrs  \n",
       "29                                   aereo    7 to 10 Yrs  \n",
       "30  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "31            varite india private limited     4 to 7 Yrs  \n",
       "32  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "33  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "34                  future solution centre   10 to 20 Yrs  \n",
       "35      rianshi developers private limited   10 to 20 Yrs  \n",
       "36                      vaishnavi services  15 to >25 Yrs  \n",
       "37                yogita staffing solution     0 to 3 Yrs  \n",
       "38                 pick bright hr solution      0 to 1 Yr  \n",
       "39                      renuka interprises     0 to 4 Yrs  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'title':job_titles,'location':job_location,'company_name':company_name,'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0b482",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.shine.com/\n",
    "# 2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6409da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f484d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe281d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "90dffbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter designation as required in the question\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c525b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a38025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15547a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7494871",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf2d42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags:\n",
    "    titles=i.text\n",
    "    job_titles.append(titles)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9a5fdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0741ec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML Data Scientist</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist/ Principal Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pharma Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Full time Opportunity-Networking Advisor-Cisco...</td>\n",
       "      <td>Bangalore\\n+5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title        location\n",
       "0                                   ML Data Scientist   Bangalore\\n+3\n",
       "1                       Data Scientist Urgent Vacancy  Bangalore\\n+15\n",
       "2                          Data Scientist Recruitment  Bangalore\\n+15\n",
       "3                          Data Scientist Recruitment  Bangalore\\n+15\n",
       "4                                      Data Scientist   Bangalore\\n+4\n",
       "5                                      Data Scientist       Bangalore\n",
       "6       Lead Data Scientist/ Principal Data Scientist   Bangalore\\n+1\n",
       "7   Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14\n",
       "8                               Senior Data Scientist   Bangalore\\n+1\n",
       "9                                 Lead Data Scientist   Bangalore\\n+1\n",
       "10                                     Data Scientist   Bangalore\\n+7\n",
       "11                      Data Scientist Urgent Vacancy  Bangalore\\n+14\n",
       "12                                     Data Scientist   Bangalore\\n+2\n",
       "13                              Pharma Data Scientist   Bangalore\\n+4\n",
       "14                          Hiring For Data Scientist  Bangalore\\n+13\n",
       "15                          Hiring For Data Scientist  Bangalore\\n+14\n",
       "16                      Data Scientist Urgent Vacancy  Bangalore\\n+13\n",
       "17                         Data Scientist Recruitment  Bangalore\\n+13\n",
       "18                                     Data Scientist       Bangalore\n",
       "19  Full time Opportunity-Networking Advisor-Cisco...   Bangalore\\n+5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'title':job_titles,'location':job_location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595060c8",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "#  You have to use the location and salary filter.\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "# You have to scrape the job-title, job-location, company name, experience required.\n",
    "# The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "# The task will be done as shown in the below steps:\n",
    "# 1. first get the web page https://www.shine.com/\n",
    "# 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "# 5. Then scrape the data for the first 10 jobs results you get.\n",
    "# 6. Finally create a dataframe of the scrapeddata.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5012f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bd55c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "45c9af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7fbb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter designation as required in the question\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul[1]/li[1]/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aafd81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul[1]/li[2]/div/input\")\n",
    "location.send_keys('Delhi-ncr Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "daa4a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul[2]/li[1]/div/input[1]\")\n",
    "salary.send_keys('3-6 lakhs')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "64f94d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22a34d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7cfb89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags:\n",
    "    titles=i.text\n",
    "    job_titles.append(titles)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "# scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "# scarping job expreience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "209c9237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fdb2bb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram\\n+1</td>\n",
       "      <td>right advisors private limited</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>thescholarhat</td>\n",
       "      <td>1 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Japanese language</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>right advisors private limited</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DataNeuron - Senior Data Scientist - NLP</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>dataneuron</td>\n",
       "      <td>3 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>adept global</td>\n",
       "      <td>3 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>roadzen</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>buddy4study</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>scrolltab</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior/Lead Data Scientist- Noida/Bangalore/Hy...</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>techneplus</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>info edge india ltd</td>\n",
       "      <td>1 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist at WinZO</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>winzone technology pvt ltd</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>reddoorz</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Immediate opening for Data Scientist- Delhi (H...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>htc global services</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>chegg india</td>\n",
       "      <td>5 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>arya.ag</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCG X Lead Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>boston consulting group</td>\n",
       "      <td>9 to 13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>tcns clothing company ltd</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida\\n+1</td>\n",
       "      <td>adobe</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+7</td>\n",
       "      <td>people staffing solutions</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title      location  \\\n",
       "0                                      Data Scientist  Gurugram\\n+1   \n",
       "1                                      Data Scientist     Delhi\\n+4   \n",
       "2                                      Data Scientist     Noida\\n+1   \n",
       "3                  Data Scientist - Japanese language         Delhi   \n",
       "4            DataNeuron - Senior Data Scientist - NLP         Delhi   \n",
       "5                                      Data Scientist         Delhi   \n",
       "6                               Senior Data Scientist         Delhi   \n",
       "7                               Python Data Scientist     Noida\\n+1   \n",
       "8                                      Data Scientist         Delhi   \n",
       "9   Senior/Lead Data Scientist- Noida/Bangalore/Hy...     Noida\\n+1   \n",
       "10                                     Data Scientist     Noida\\n+1   \n",
       "11                            Data Scientist at WinZO         Delhi   \n",
       "12                                     Data Scientist     Noida\\n+1   \n",
       "13  Immediate opening for Data Scientist- Delhi (H...         Delhi   \n",
       "14                              Senior Data Scientist         Delhi   \n",
       "15                                     Data Scientist     Noida\\n+1   \n",
       "16                          BCG X Lead Data Scientist         Delhi   \n",
       "17                              Senior Data Scientist         Delhi   \n",
       "18                                     Data Scientist     Noida\\n+1   \n",
       "19                                     Data Scientist     Delhi\\n+7   \n",
       "\n",
       "                      company_name   experience  \n",
       "0   right advisors private limited   2 to 7 Yrs  \n",
       "1    acme services private limited   3 to 5 Yrs  \n",
       "2                    thescholarhat   1 to 3 Yrs  \n",
       "3   right advisors private limited   5 to 8 Yrs  \n",
       "4                       dataneuron   3 to 4 Yrs  \n",
       "5                     adept global   3 to 7 Yrs  \n",
       "6                          roadzen   5 to 9 Yrs  \n",
       "7                      buddy4study   4 to 8 Yrs  \n",
       "8                        scrolltab   4 to 8 Yrs  \n",
       "9                       techneplus   3 to 8 Yrs  \n",
       "10             info edge india ltd   1 to 5 Yrs  \n",
       "11      winzone technology pvt ltd   0 to 3 Yrs  \n",
       "12                        reddoorz   2 to 7 Yrs  \n",
       "13             htc global services   3 to 5 Yrs  \n",
       "14                     chegg india   5 to 7 Yrs  \n",
       "15                         arya.ag   2 to 6 Yrs  \n",
       "16         boston consulting group  9 to 13 Yrs  \n",
       "17       tcns clothing company ltd   2 to 4 Yrs  \n",
       "18                           adobe   5 to 9 Yrs  \n",
       "19       people staffing solutions   4 to 9 Yrs  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'title':job_titles,'location':job_location,'company_name':company_name,'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d931c",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "# 6. Brand\n",
    "# 7. ProductDescription\n",
    "# 8. Price\n",
    "# The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "# To scrape the data you have to go through following steps:\n",
    "# 1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "# 2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and click the search icon\n",
    "# 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "# 4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "# 5. Now scrape data from this page as usual\n",
    "# 6. Repeat this until you get data for 100sunglasses.\n",
    "# Note: That all of the above steps have to be done by coding only and not manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7905f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e726b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "48fd5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d9edd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglass=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "sunglass.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c3a67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f573deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "ProductDescription=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9ff52151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand title from the given page\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    titles=i.text\n",
    "    Brand.append(titles)\n",
    "    \n",
    "# scraping productdescription from the given page\n",
    "ProductDescription_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in ProductDescription_tags:\n",
    "    product=i.text\n",
    "    ProductDescription.append(product)\n",
    "    \n",
    "# scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2ff3b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f699774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3b908b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Retro Square Sunglas...</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Clubmaste...</td>\n",
       "      <td>₹811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Round Sunglasses</td>\n",
       "      <td>₹4,188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                product_description   price\n",
       "0    VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...    ₹499\n",
       "1         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹539\n",
       "2         Fastrack        UV Protection Shield Sunglasses (Free Size)    ₹619\n",
       "3         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹549\n",
       "4    VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹556\n",
       "..             ...                                                ...     ...\n",
       "115  VINCENT CHASE  by Lenskart UV Protection Retro Square Sunglas...    ₹569\n",
       "116  VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...    ₹816\n",
       "117  VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...    ₹816\n",
       "118  VINCENT CHASE  by Lenskart Polarized, UV Protection Clubmaste...    ₹811\n",
       "119        Ray-Ban                     UV Protection Round Sunglasses  ₹4,188\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'brand':Brand,'product_description':ProductDescription,'price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c7337",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "# https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "# As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "# 1. Rating\n",
    "# 2. Review summary\n",
    "# 3. Full review\n",
    "# 4. You have to scrape this data for first 100reviews.\n",
    "# Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d2bc7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c6a41b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f33ae82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a3da2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0ae9a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand title from the given page\n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rates=i.text\n",
    "    Rating.append(rates)\n",
    "    \n",
    "# scraping productdescription from the given page\n",
    "review_summary_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_summary_tags:\n",
    "    review=i.text\n",
    "    Review_summary.append(review)\n",
    "    \n",
    "# scraping price from the given page\n",
    "full_review_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_review_tags:\n",
    "    full_review=i.text\n",
    "    Full_review.append(full_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b95b07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8e1044cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       review_summary                         full_review\n",
       "0       5     Perfect product!  Outstanding performance this phone\n",
       "1       5            Wonderful  Outstanding performance this phone\n",
       "2       5             Terrific  Outstanding performance this phone\n",
       "3       5       Classy product  Outstanding performance this phone\n",
       "4       5  Best in the market!  Outstanding performance this phone\n",
       "..    ...                  ...                                 ...\n",
       "95      5   Highly recommended  Outstanding performance this phone\n",
       "96      5            Wonderful  Outstanding performance this phone\n",
       "97      4            Very Good  Outstanding performance this phone\n",
       "98      5            Brilliant  Outstanding performance this phone\n",
       "99      5       Classy product  Outstanding performance this phone\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'rating':Rating,'review_summary':Review_summary,'full_review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6b278",
   "metadata": {},
   "source": [
    "# Q6: Scrape data forfirst 100 sneakers you find whenyou visit flipkart.com and search for “sneakers” inthe\n",
    "# search field.\n",
    "# You have to scrape 3 attributes of each sneaker:\n",
    "# 1. Brand\n",
    "# 2. ProductDescription\n",
    "# 3. Price\n",
    "# As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0594e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6734188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3cc78c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cc959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "59b044b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "sneakers.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b60e8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "0a191702",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "ProductDescription=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a4e9f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand title from the given page\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    titles=i.text\n",
    "    Brand.append(titles)\n",
    "    \n",
    "# scraping productdescription from the given page\n",
    "ProductDescription_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in ProductDescription_tags:\n",
    "    product=i.text\n",
    "    ProductDescription.append(product)\n",
    "    \n",
    "# scraping price from the given page\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "cb3922ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b2dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "29da82f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Suede Classic XXI Sneakers For Men</td>\n",
       "      <td>₹2,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Suede Classic XXI Sneakers For Men</td>\n",
       "      <td>₹3,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Court Star Vulc FS Sneakers For Men</td>\n",
       "      <td>₹2,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rs-z Bp Sneakers For Men</td>\n",
       "      <td>₹4,213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Twitch Runner Sneakers For Men</td>\n",
       "      <td>₹3,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rebound Street v2 L Sneakers For Men</td>\n",
       "      <td>₹2,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>RS-X Master Sneakers For Men</td>\n",
       "      <td>₹5,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Cell Venom Alert Running Shoes For Men</td>\n",
       "      <td>₹5,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Arbok</td>\n",
       "      <td>Arbok Trendy Casuals For Men</td>\n",
       "      <td>₹490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Arbok</td>\n",
       "      <td>Arbok Trendy Casuals For Men</td>\n",
       "      <td>₹490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                     product_description   price\n",
       "0    PUMA      Suede Classic XXI Sneakers For Men  ₹2,799\n",
       "1    PUMA      Suede Classic XXI Sneakers For Men  ₹3,899\n",
       "2    PUMA     Court Star Vulc FS Sneakers For Men  ₹2,399\n",
       "3    PUMA                Rs-z Bp Sneakers For Men  ₹4,213\n",
       "4    PUMA          Twitch Runner Sneakers For Men  ₹3,999\n",
       "..    ...                                     ...     ...\n",
       "95   PUMA    Rebound Street v2 L Sneakers For Men  ₹2,399\n",
       "96   PUMA            RS-X Master Sneakers For Men  ₹5,399\n",
       "97   PUMA  Cell Venom Alert Running Shoes For Men  ₹5,999\n",
       "98  Arbok            Arbok Trendy Casuals For Men    ₹490\n",
       "99  Arbok            Arbok Trendy Casuals For Men    ₹490\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'brand':Brand,'product_description':ProductDescription,'price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e96bb",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "# After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "# 1. Title\n",
    "# 2. Ratings\n",
    "# 3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c414fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e43a3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b46ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58813795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/?&tag=googhydrabk1-21&ref=pd_sl_7hz2t19t5c_e&adgrpid=155259815513&hvpone=&hvptwo=&hvadid=674842289437&hvpos=&hvnetw=g&hvrand=12753365725127441909&hvqmt=e&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9062122&hvtargid=kwd-10573980&hydadcr=14453_2316415&gad_source=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7e1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6696c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product_name.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "142c64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1499f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_=[]\n",
    "Ratings_=[]\n",
    "Price_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56910f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags:\n",
    "    titles=i.text\n",
    "    Title_.append(titles)\n",
    "# scraping rating from the given page\n",
    "rating_tag=driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for i in rating_tag:\n",
    "    rate=i.text\n",
    "    Ratings_.append(rate)\n",
    "    \n",
    "# scraping price from the given page\n",
    "price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tag:\n",
    "    price=i.text\n",
    "    Price_.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb6dc96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "print(len(Title_),len(Price_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd0bc002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>(rs)price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>73,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>54,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>62,032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 16X, Intel Core i7-12650H 12th G...</td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 13700H 16\"...</td>\n",
       "      <td>87,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI Modern 15, Intel 13th Gen. i7-1355U, 40CM ...</td>\n",
       "      <td>65,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GIGABYTE G5 MF-G2IN313SH Gaming Laptop Intel C...</td>\n",
       "      <td>75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td>67,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>77,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dell Inspiron 3530 Laptop, Intel Core i7-1355U...</td>\n",
       "      <td>71,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dell Alienware x14 R2 Gaming Laptop, Intel Cor...</td>\n",
       "      <td>2,25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSI Pulse 15, Intel 13th Gen. i7-13700H, 40CM ...</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HP OMEN Gaming Laptop, Intel Core i7-14700HX (...</td>\n",
       "      <td>1,50,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASUS Vivobook S 15 OLED (2023), Intel Core EVO...</td>\n",
       "      <td>1,02,481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HP Victus 12th Gen Intel Core i7 15.6 inch(39....</td>\n",
       "      <td>82,777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...</td>\n",
       "      <td>78,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-1195G7,...</td>\n",
       "      <td>72,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HP Envy x360 12th Gen Intel Core i7-13.3 inch(...</td>\n",
       "      <td>1,14,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dell G16-7630 Gaming 13th Gen Laptop, Intel i7...</td>\n",
       "      <td>1,66,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HP Victus Gaming Laptop 12th Gen Intel Core i7...</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Microsoft New Surface Laptop5 15\" Intel evo 12...</td>\n",
       "      <td>1,82,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title (rs)price\n",
       "0   ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...    73,990\n",
       "1   MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...    54,820\n",
       "2   Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...    62,032\n",
       "3   ASUS Vivobook 16X, Intel Core i7-12650H 12th G...  1,04,990\n",
       "4   Lenovo IdeaPad Slim 5 Intel Core i7 13700H 16\"...    87,190\n",
       "5   ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...    64,990\n",
       "6   MSI Modern 15, Intel 13th Gen. i7-1355U, 40CM ...    65,990\n",
       "7   HP Pavilion X360 11th Gen Intel Core i7 14\" (3...    77,990\n",
       "8   GIGABYTE G5 MF-G2IN313SH Gaming Laptop Intel C...    75,990\n",
       "9   HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...    67,490\n",
       "10  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    77,590\n",
       "11  Dell Inspiron 3530 Laptop, Intel Core i7-1355U...    71,490\n",
       "12  Dell Alienware x14 R2 Gaming Laptop, Intel Cor...  2,25,990\n",
       "13  MSI Pulse 15, Intel 13th Gen. i7-13700H, 40CM ...  1,29,990\n",
       "14  Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...    86,990\n",
       "15  HP OMEN Gaming Laptop, Intel Core i7-14700HX (...  1,50,990\n",
       "16  ASUS Vivobook S 15 OLED (2023), Intel Core EVO...  1,02,481\n",
       "17  HP Victus 12th Gen Intel Core i7 15.6 inch(39....    82,777\n",
       "18  ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...    78,060\n",
       "19  HP Pavilion 14, 11th Gen Intel Core i7-1195G7,...    72,100\n",
       "20  HP Envy x360 12th Gen Intel Core i7-13.3 inch(...  1,14,990\n",
       "21  Dell G16-7630 Gaming 13th Gen Laptop, Intel i7...  1,66,490\n",
       "22  HP Victus Gaming Laptop 12th Gen Intel Core i7...    97,990\n",
       "23  Microsoft New Surface Laptop5 15\" Intel evo 12...  1,82,990"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'title':Title_,'(rs)price':Price_})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279269c2",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "# The above task will be done in following steps:\n",
    "# 1. First get the webpagehttps://www.azquotes.com/\n",
    "# 2. Click on TopQuotes\n",
    "# 3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59b65276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ac64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ce07591",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21c71889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the azquotes page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3376920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60a3775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote=[]\n",
    "Author=[] \n",
    "Type_Of_Quotes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01ff8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping quote  from the given page\n",
    "quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    titles=i.text\n",
    "    Quote.append(titles)\n",
    "# scraping author from the given page\n",
    "author_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in author_tag:\n",
    "    tag=i.text\n",
    "    Author.append(tag)\n",
    "    \n",
    "# scraping type of quote from the given page\n",
    "type_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in type_tag:\n",
    "    quote=i.text\n",
    "    Type_Of_Quotes.append(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f7c6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(Type_Of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "045ae31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>type_of_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 quote              author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                               type_of_quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'quote':Quote,'author':Author,'type_of_quotes':Type_Of_Quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fad52",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpagehttps://www.jagranjosh.com/\n",
    "# 2. Then You have to click on the GK option\n",
    "# 3. Then click on the List of all Prime Ministers of India\n",
    "# 4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f363061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93f8a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc5fe19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the jagranjosh page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1b7fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div/div/div[3]/ul/li[3]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e717a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[8]/section[17]/div/div/ul[2]/li[11]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "429f9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc548ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code are not going to work because there is no seperate among the row and column code\n",
    "# scraping name  from the given page\n",
    "name_tags=driver.find_elements(By.XPATH,'')\n",
    "for i in name_tags:\n",
    "    titles=i.text\n",
    "    Name.append(titles)\n",
    "# scraping born_dead from the given page\n",
    "born_dead_tag=driver.find_elements(By.XPATH,'')\n",
    "for i in born_dead_tag:\n",
    "    tag=i.text\n",
    "    Born_Dead.append(tag)\n",
    "    \n",
    "# scraping term_of_office from the given page\n",
    "term_of_office_tag=driver.find_elements(By.XPATH,'')\n",
    "for i in term_of_office_tag:\n",
    "    office=i.text\n",
    "    Term_of_office.append(office)\n",
    "# scraping remark from the given page    \n",
    "remark_tag=driver.find_elements(By.XPATH,'')\n",
    "for i in remark_tag:\n",
    "    remark=i.text\n",
    "    Remarks.append(remark)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64892e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping name  from the given page\n",
    "name_tags=driver.find_elements(By.XPATH,'//td[@valign=\"top\"]')\n",
    "for i in name_tags:\n",
    "    titles=i.text\n",
    "    Name.append(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44878d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11898f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1889–1964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>18.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Narendra Modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(born 1950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name\n",
       "0                                                  1.\n",
       "1                                   Jawahar Lal Nehru\n",
       "2                                         (1889–1964)\n",
       "3   15 August 1947 to 27 May 1964\\n16 years, 286 days\n",
       "4   The first prime minister of India and the long...\n",
       "..                                                ...\n",
       "80                                                18.\n",
       "81                                      Narendra Modi\n",
       "82                                        (born 1950)\n",
       "83                                 26 May 2014 - 2019\n",
       "84  4th Prime Minister of India who served two con...\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'name':Name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3787e9",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.motor1.com/\n",
    "# 2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "# 3. Then click on 50 most expensive carsin the world..\n",
    "# 4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e45426f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00fed807",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9588f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the motor car page on automated chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f655c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_car=driver.find_element(By.XPATH,\"/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input\")\n",
    "expensive_car.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c3bd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66537b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d080fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_name=[]  \n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95e16509",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_name:\n",
    "    titles=i.text\n",
    "    Car_name.append(titles)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//p[strong]')\n",
    "for i in price_tag:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "990d27c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(Car_name),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d08b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aston Martin Valour</td>\n",
       "      <td>Price: $1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "      <td>Price: $2.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "      <td>Price: $4.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>777 Hypercar</td>\n",
       "      <td>Price: $7.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce La Rose Noire Droptail</td>\n",
       "      <td>Price: $30 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              car_name                        price\n",
       "0                  Aston Martin Valour          Price: $1.5 Million\n",
       "1                         McLaren Elva          Price: $1.7 Million\n",
       "2                          Czinger 21C          Price: $1.7 Million\n",
       "3                        Ferrari Monza          Price: $1.7 Million\n",
       "4                   Gordon Murray T.33          Price: $1.7 Million\n",
       "5                    Koenigsegg Gemera          Price: $1.7 Million\n",
       "6                          Zenvo TSR-S          Price: $1.7 Million\n",
       "7                   Hennessey Venom F5          Price: $1.8 Million\n",
       "8                      Bentley Bacalar          Price: $1.9 Million\n",
       "9        Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "10              Bentley Mulliner Batur          Price: $2.0 Million\n",
       "11                        Deus Vayanne          Price: $2.0 Million\n",
       "12                         SSC Tuatara          Price: $2.0 Million\n",
       "13                         Lotus Evija          Price: $2.1 Million\n",
       "14                 Aston Martin Vulcan          Price: $2.3 Million\n",
       "15                          Delage D12          Price: $2.3 Million\n",
       "16                 Ferrari Daytona SP3          Price: $2.3 Million\n",
       "17                   McLaren Speedtail          Price: $2.3 Million\n",
       "18                        Rimac Nevera          Price: $2.4 Million\n",
       "19                       Pagani Utopia          Price: $2.5 Million\n",
       "20                Pininfarina Battista          Price: $2.5 Million\n",
       "21                  Gordon Murray T.50          Price: $2.6 Million\n",
       "22                Lamborghini Countach          Price: $2.6 Million\n",
       "23            Mercedes-AMG Project One          Price: $2.7 Million\n",
       "24                        Zenvo Aurora          Price: $2.8 Million\n",
       "25                 Aston Martin Victor          Price: $3.0 Million\n",
       "26         Hennessey Venom F5 Roadster                 $3.0 Million\n",
       "27                    Koenigsegg Jesko          Price: $3.0 Million\n",
       "28               Aston Martin Valkyrie          Price: $3.2 Million\n",
       "29           W Motors Lykan Hypersport          Price: $3.4 Million\n",
       "30                       McLaren Solus                 $3.5 Million\n",
       "31                    Lamborghini Sian          Price: $3.6 million\n",
       "32                    Koenigsegg CC850          Price: $3.7 Million\n",
       "33     Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
       "34                  Lamborghini Veneno          Price: $4.5 Million\n",
       "35                      Bugatti Bolide          Price: $4.7 Million\n",
       "36           Pininfarina B95 Speedster          Price: $4.8 Million\n",
       "37                     Bugatti Mistral          Price: $5.0 Million\n",
       "38                 Pagani Huayra Imola          Price: $5.4 Million\n",
       "39                        Bugatti Divo          Price: $5.8 Million\n",
       "40                 SP Automotive Chaos          Price: $6.4 Million\n",
       "41                    Pagani Codalunga          Price: $7.4 Million\n",
       "42                        777 Hypercar          Price: $7.5 Million\n",
       "43            Mercedes-Maybach Exelero          Price: $8.0 Million\n",
       "44                  Bugatti Centodieci          Price: $9.0 Million\n",
       "45             Bugatti Chiron Profilée         Price: $10.8 Million\n",
       "46                Rolls-Royce Sweptail         Price: $12.8 Million\n",
       "47            Bugatti La Voiture Noire         Price: $13.4 Million\n",
       "48              Rolls-Royce Boat Tail*  Price: $28.0 Million (est.)\n",
       "49  Rolls-Royce La Rose Noire Droptail    Price: $30 Million (est.)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'car_name':Car_name,'price':Price})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
